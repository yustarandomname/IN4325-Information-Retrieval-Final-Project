{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "Libraries used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: deep-translator in ./.venv/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: python-terrier==0.10.0 in ./.venv/lib/python3.10/site-packages (0.10.0)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (2.2.1)\n",
      "Requirement already satisfied: wget in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (3.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (4.66.2)\n",
      "Requirement already satisfied: pyjnius>=1.4.2 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.6.1)\n",
      "Requirement already satisfied: matchpy in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.5.5)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.4.1.post1)\n",
      "Requirement already satisfied: deprecated in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.2.14)\n",
      "Requirement already satisfied: chest in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.2.3)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.12.0)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (2.31.0)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.3.2)\n",
      "Requirement already satisfied: nptyping==1.4.4 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (1.4.4)\n",
      "Requirement already satisfied: more-itertools in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (10.2.0)\n",
      "Requirement already satisfied: ir-datasets>=0.3.2 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.5.6)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (3.1.3)\n",
      "Requirement already satisfied: statsmodels in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.14.1)\n",
      "Requirement already satisfied: ir-measures>=0.3.1 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.3.3)\n",
      "Requirement already satisfied: dill in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.3.8)\n",
      "Requirement already satisfied: pytrec-eval-terrier>=0.5.3 in ./.venv/lib/python3.10/site-packages (from python-terrier==0.10.0) (0.5.6)\n",
      "Requirement already satisfied: typish>=1.7.0 in ./.venv/lib/python3.10/site-packages (from nptyping==1.4.4->python-terrier==0.10.0) (1.9.3)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in ./.venv/lib/python3.10/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: inscriptis>=2.2.0 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (2.5.0)\n",
      "Requirement already satisfied: lxml>=4.5.2 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (5.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (6.0.1)\n",
      "Requirement already satisfied: trec-car-tools>=2.5.4 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (2.6)\n",
      "Requirement already satisfied: lz4>=3.1.10 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (4.3.3)\n",
      "Requirement already satisfied: warc3-wet>=0.2.3 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (0.2.3)\n",
      "Requirement already satisfied: warc3-wet-clueweb09>=0.2.5 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (0.2.5)\n",
      "Requirement already satisfied: zlib-state>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (0.1.6)\n",
      "Requirement already satisfied: ijson>=3.1.3 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (3.2.3)\n",
      "Requirement already satisfied: pyautocorpus>=0.1.1 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (0.1.12)\n",
      "Requirement already satisfied: unlzw3>=0.2.1 in ./.venv/lib/python3.10/site-packages (from ir-datasets>=0.3.2->python-terrier==0.10.0) (0.2.2)\n",
      "Requirement already satisfied: cwl-eval>=1.0.10 in ./.venv/lib/python3.10/site-packages (from ir-measures>=0.3.1->python-terrier==0.10.0) (1.0.12)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->python-terrier==0.10.0) (2024.2.2)\n",
      "Requirement already satisfied: heapdict in ./.venv/lib/python3.10/site-packages (from chest->python-terrier==0.10.0) (1.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in ./.venv/lib/python3.10/site-packages (from deprecated->python-terrier==0.10.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->python-terrier==0.10.0) (2.1.5)\n",
      "Requirement already satisfied: multiset<3.0,>=2.0 in ./.venv/lib/python3.10/site-packages (from matchpy->python-terrier==0.10.0) (2.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.10/site-packages (from pandas->python-terrier==0.10.0) (2024.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.10/site-packages (from scikit-learn->python-terrier==0.10.0) (3.4.0)\n",
      "Requirement already satisfied: patsy>=0.5.4 in ./.venv/lib/python3.10/site-packages (from statsmodels->python-terrier==0.10.0) (0.5.6)\n",
      "Requirement already satisfied: packaging>=21.3 in ./.venv/lib/python3.10/site-packages (from statsmodels->python-terrier==0.10.0) (24.0)\n",
      "Requirement already satisfied: six in ./.venv/lib/python3.10/site-packages (from patsy>=0.5.4->statsmodels->python-terrier==0.10.0) (1.16.0)\n",
      "Requirement already satisfied: cbor>=1.0.0 in ./.venv/lib/python3.10/site-packages (from trec-car-tools>=2.5.4->ir-datasets>=0.3.2->python-terrier==0.10.0) (1.0.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy deep-translator python-dotenv python-terrier==0.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "env = dotenv_values(\".env\")  # replace \".env.example\" with .env file path\n",
    "\n",
    "if (env[\"LANGUAGE_DETECT_API_KEY\"] == \"YOUR API KEY\"):\n",
    "  raise Exception(\"Please replace 'YOUR API KEY' with your actual API key in the .env file\")\n",
    "\n",
    "detection_api_key = env[\"LANGUAGE_DETECT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import threading\n",
    "\n",
    "import deep_translator as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyterrier as pt\n",
    "from deep_translator import GoogleTranslator, single_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "deep-translator version: 1.9.1\n",
      "pyterrier version: 0.10.0\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"deep-translator version:\", dt.__version__)\n",
    "print(\"pyterrier version:\", pt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTerrier 0.10.0 has loaded Terrier 5.8 (built by craigm on 2023-11-01 18:05) and terrier-helper 0.0.8\n",
      "\n",
      "No etc/terrier.properties, using terrier.default.properties for bootstrap configuration.\n"
     ]
    }
   ],
   "source": [
    "if not pt.started():\n",
    "    pt.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Query formulation\n",
    "\n",
    "Let the end-user determine what they would like to find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = \"How do I repair my bike?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query language identification\n",
    "\n",
    "Identify the language of the query with the help of the ... library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "l0 = single_detection(q0, api_key=detection_api_key)\n",
    "print(l0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query translation\n",
    "\n",
    "Translate the query into Dutch, English, French, German, Italian, Portuguese, Russian, Spanish, and Chineese. Exlude the original language of the query from the translation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'en': 'How do I repair my bike?',\n",
       " 'it': 'Come riparo la mia bicicletta?',\n",
       " 'es': '¿Cómo reparo mi bicicleta?',\n",
       " 'fr': 'Comment réparer mon vélo ?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qs = dict({l0: q0})\n",
    "\n",
    "languages = [\"en\", \"fr\", \"it\", \"es\"]\n",
    "\n",
    "threads = []\n",
    "\n",
    "def translate(lang):\n",
    "    gt = GoogleTranslator(source=l0, target=lang)\n",
    "    translated = gt.translate(text=q0)\n",
    "    qs[lang] = translated\n",
    "\n",
    "\n",
    "for lang in languages:\n",
    "    if lang != l0:\n",
    "        t1 = threading.Thread(target=translate, args=(lang,))\n",
    "        t1.start()\n",
    "        threads.append(t1)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()\n",
    "\n",
    "qs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search for documents in the target language\n",
    "\n",
    "Search for documents in the target language using the translated queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. MLWIKIR: APython toolkit for building large-scale Wikipedia-based Information Retrieval Datasets in Chinese, English, French, Italian, Japanese, Spanish and more. [Research paper](https://www.irit.fr/CIRCLE/wp-content/uploads/2020/06/CIRCLE20_22.pdf)\n",
    "1. [pyterrier jupyter notebook example of spanish document retreival](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/non_en_retrieval.ipynb)\n",
    "1. [WikIR rawa datasets](https://ir-datasets.com/wikir.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Indexing of the documents\n",
    "If the index of the documents is not available, then the documents will be indexed using the pyterrier library.\n",
    "Otherwise, the index will be loaded from the disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_index(dataset: str, index_name: str, fields=[\"text\"]): \n",
    "    \"\"\"\n",
    "    Creates an index for a given dataset using the specified index name and fields.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset: The dataset object containing the corpus to be indexed.\n",
    "    - index_name: The name of the index to be created.\n",
    "    - fields: A list of fields to be indexed. Default is [\"text\"].\n",
    "\n",
    "    Returns:\n",
    "    - index_ref: The reference to the created index.\n",
    "\n",
    "    \"\"\"\n",
    "    indexer = pt.IterDictIndexer(\"./indices/\" + index_name, verbose=False)\n",
    "    index_ref = indexer.index(dataset.get_corpus_iter(), fields=fields)\n",
    "    return index_ref\n",
    "\n",
    "\n",
    "def find_index(index_name: str):\n",
    "    \"\"\"\n",
    "    Finds the reference to an existing index with the specified name.\n",
    "\n",
    "    Parameters:\n",
    "    - index_name: The name of the index to be found.\n",
    "\n",
    "    Returns:\n",
    "    - index_ref: The reference to the found index.\n",
    "\n",
    "    \"\"\"\n",
    "    return pt.IndexRef.of(\"./indices/\" + index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index wikir_fr14k already exists\n",
      "Index wikir_es13k already exists\n",
      "Index wikir_en1k already exists\n",
      "Index wikir_it16k already exists\n",
      "{'fr': <org.terrier.querying.IndexRef at 0x1244a3d30 jclass=org/terrier/querying/IndexRef jself=<LocalRef obj=0x123519b38 at 0x1343224f0>>, 'es': <org.terrier.querying.IndexRef at 0x124504900 jclass=org/terrier/querying/IndexRef jself=<LocalRef obj=0x123519b68 at 0x134322e70>>, 'en': <org.terrier.querying.IndexRef at 0x1340efc90 jclass=org/terrier/querying/IndexRef jself=<LocalRef obj=0x123519b80 at 0x134322e10>>, 'it': <org.terrier.querying.IndexRef at 0x1344a44f0 jclass=org/terrier/querying/IndexRef jself=<LocalRef obj=0x123519b88 at 0x134321ff0>>}\n"
     ]
    }
   ],
   "source": [
    "datasetNames: dict[str, str] = dict({\"fr\":\"wikir/fr14k\", \"es\": \"wikir/es13k\", \"en\":\"wikir/en1k\", \"it\":\"wikir/it16k\"})\n",
    "datasets = dict()\n",
    "indeces = dict()\n",
    "\n",
    "def index(dataset: str, index_name: str, fields=[\"text\"]):\n",
    "    index_ref = create_index(dataset, index_name, fields)\n",
    "    indeces[lang] = index_ref\n",
    "\n",
    "index_threads = []\n",
    "\n",
    "for [lang, datasetName] in datasetNames.items():\n",
    "    datasetFolder = datasetName.replace(\"/\", \"_\")\n",
    "    dataset = pt.get_dataset(\"irds:\"+datasetName)\n",
    "    datasets[lang] = dataset\n",
    "\n",
    "    if os.path.exists(\"./indices/\" + datasetFolder + \"/data.properties\"):\n",
    "        print(\"Index\", datasetFolder, \"already exists\")\n",
    "        index_ref = find_index(datasetFolder)\n",
    "        indeces[lang] = index_ref\n",
    "    else:\n",
    "        print(\"Creating index\", datasetFolder, \" (takes around 1-3 minutes per dataset)\")\n",
    "        thread = threading.Thread(target=index, args=(dataset, datasetFolder))\n",
    "        thread.start()\n",
    "        index_threads.append(thread)\n",
    "\n",
    "for thread in index_threads:\n",
    "    thread.join()\n",
    "\n",
    "print(indeces)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Retrieval of the documents\n",
    "The documents will be retrieved using the BM25 retrieval model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comment rparer mon vlo '"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"[^a-zA-Z0-9 ]\", \"\", qs['fr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results for fr Index(['qid', 'docid', 'docno', 'rank', 'score', 'query', 'text'], dtype='object') - shape: (20, 7) top 5:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>401968</td>\n",
       "      <td>403301</td>\n",
       "      <td>0</td>\n",
       "      <td>21.629457</td>\n",
       "      <td>Comment rparer mon vlo</td>\n",
       "      <td>elle est issue de la fusion en 1981 de l opéra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>485591</td>\n",
       "      <td>487240</td>\n",
       "      <td>1</td>\n",
       "      <td>21.287983</td>\n",
       "      <td>Comment rparer mon vlo</td>\n",
       "      <td>elle suit la guérison d un possédé muet et fai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>195615</td>\n",
       "      <td>196210</td>\n",
       "      <td>2</td>\n",
       "      <td>19.694506</td>\n",
       "      <td>Comment rparer mon vlo</td>\n",
       "      <td>pour saluer bien bas on fait acte de soumissio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>163481</td>\n",
       "      <td>164009</td>\n",
       "      <td>3</td>\n",
       "      <td>19.581240</td>\n",
       "      <td>Comment rparer mon vlo</td>\n",
       "      <td>l histoire raconte comment les personnages des...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>129221</td>\n",
       "      <td>129661</td>\n",
       "      <td>4</td>\n",
       "      <td>19.424128</td>\n",
       "      <td>Comment rparer mon vlo</td>\n",
       "      <td>le dæmon serait donc en quelque sorte la manif...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid   docid   docno  rank      score                    query  \\\n",
       "0   1  401968  403301     0  21.629457  Comment rparer mon vlo    \n",
       "1   1  485591  487240     1  21.287983  Comment rparer mon vlo    \n",
       "2   1  195615  196210     2  19.694506  Comment rparer mon vlo    \n",
       "3   1  163481  164009     3  19.581240  Comment rparer mon vlo    \n",
       "4   1  129221  129661     4  19.424128  Comment rparer mon vlo    \n",
       "\n",
       "                                                text  \n",
       "0  elle est issue de la fusion en 1981 de l opéra...  \n",
       "1  elle suit la guérison d un possédé muet et fai...  \n",
       "2  pour saluer bien bas on fait acte de soumissio...  \n",
       "3  l histoire raconte comment les personnages des...  \n",
       "4  le dæmon serait donc en quelque sorte la manif...  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "document_data: dict[str, pd.DataFrame] = dict()\n",
    "NUM_RESULTS = 20\n",
    "\n",
    "for lang in languages:\n",
    "    index_ref = indeces[lang]\n",
    "    dataset = datasets[lang]\n",
    "\n",
    "    pipeline = pt.BatchRetrieve(\n",
    "        index_ref, wmodel=\"BM25\", metadata=[\"docno\"], num_results=NUM_RESULTS\n",
    "    ) >> pt.text.get_text(dataset, \"text\")\n",
    "\n",
    "    sanitised_query = re.sub(r\"[^a-zA-Z0-9 ]\", \"\", qs[lang])\n",
    "\n",
    "    pandas_df: pd.DataFrame = pipeline.search(sanitised_query)\n",
    "    document_data[lang] = pandas_df\n",
    "\n",
    "print(\n",
    "    \"Results for fr\",\n",
    "    document_data[\"fr\"].keys(),\n",
    "    \"- shape:\",\n",
    "    document_data[\"fr\"].shape,\n",
    "    \"top 5:\"\n",
    ")\n",
    "\n",
    "document_data[\"fr\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words in document: 200\n"
     ]
    }
   ],
   "source": [
    "top_document = document_data[\"fr\"].head(1)[\"text\"].values[0]\n",
    "\n",
    "print(\"Words in document:\", len(top_document.split(\" \")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document translation\n",
    "\n",
    "Translate the documents back to English to be processed by other algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_translated: dict[str, list[str]] = dict()\n",
    "\n",
    "def translate_document(lang: str, document_text: str, gt: GoogleTranslator):\n",
    "    translated = gt.translate(text=document_text)\n",
    "    documents_translated[lang].append(translated)\n",
    "\n",
    "threads = []\n",
    "\n",
    "for lang, docs in document_data.items():\n",
    "    documents_translated[lang] = []\n",
    "    text_docs = docs[\"text\"].tolist()\n",
    "    gt = GoogleTranslator(source=lang, target=\"en\")\n",
    "\n",
    "    for text in text_docs:\n",
    "        t = threading.Thread(target=translate_document, args=(lang, text, gt))\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "\n",
    "for t in threads:\n",
    "    t.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it resulted from the merger in 1981 of the royal Flemish opera of Antwerp and the opera of Ghent due to the financial difficulties faced by the operas of Ghent and Antwerp the intercommunal society opera for flanders opera voor flaanderen ovv was created in 1981 it involves the cities of ghent and antwerp and the Flemish community the two municipal operas were thus merged in 1986 the ovv is short of financial means and can no longer pay salaries the Flemish community refuses to intervene and the opera is occupied by staff a commission of inquiry from the Flemish council produces a harsh report for the administration of the ovv the Flemish executive implements a restructuring plan involving the dissolution of the ovv which takes place the Flemish executive considers that a quality opera must continue to exist in flanders on July 20, 1988 the non-profit association asbl vlaamse operastichting vlos foundation of flemish opera in french is created the vlos takes over most of the staff of the ovv several trials followed from which it emerged among other things that an asbl is not the',\n",
       " 'it follows the healing of a mute possessed man and alludes to the devil Jesus having healed a demoniac a mute possessed person the Pharisees suspect him of casting out demons by the prince of demons to their accusations Jesus responds that it is from God quite the contrary that he takes his healing power in support of his reasoning he produces the parable of the strong man the Pharisees having heard this said this man only casts out demons by Beelzebub prince of demons 25 as Jesus knew their thoughts he told them every kingdom divided against himself is devastated and every city or house divided against itself cannot stand 26 if satan drives out satan he is divided against himself how then will his kingdom stand 27 and if I drive out demons by beelzebub your sons by whom they drive them out therefore they themselves will be your judges 28 but if it is by the Spirit of God that I cast out demons then the kingdom of God has come to you 29 or how can anyone enter into the house of a strong man and plunder',\n",
       " \"to salute very lowly we act as an act of submission by making a curtsy exclamatory and familiar expression to greet someone a greeting can mean as well hello hello my friend hello the company it is synonymous with cuckoo from the Latin ave and yo among rappers it is also synonym of goodbye hi I'm breaking which is a synonym in this sense of English bye bye the French speaker wishes a good day or a good evening depending on the time of day and inquires about the state of his interlocutor hello how are you this greeting calls for a reassuring response followed by a reminder hello everything is going well thank you and yourself how are you the title of the interlocutor is very often interspersed hello sir how are you hello mr president how are you the greeting can be accompanied by a compliment or an emphasis hello ma'am how are you this dress looks great on you to which it is answered hello sir or madam it is fine thank you I am flattered and you yourself how are you or and you yourself what a beautiful outfit you are wearing how are you or hello dear colleague\",\n",
       " \"the story tells how the characters of the iron ladies met and how they then came together for a new volleyball tournament the film takes place in 1996 when the real team participated and won the national men's volleyball championships in thailand the two characters main characters mon and jung are two homosexual transvestites who have always been dismissed by volleyball coaches because of their extravagances and yet when a local team changes coaches the new coach leads qualifications to start a new team when mon and jung are retained most of the old players quit leaving their coach bee in a precarious situation mon and jung are then forced to enlist some of their gay and transgender friends who had played volleyball in college these new players are wit who has not yet come out as gay to his fiancée pia a transgender dancer and nong a homosexual officer in the army when the competition begins all the players on the team are homosexual or transgender except one because of their eccentricities and on the floor fancy outfits victory dance consisting of a charming\",\n",
       " 'the dæmon would therefore be in a way the physical manifestation of the soul of a human many characteristics of dæmons agree with certain concepts of psychology or anthropology in other worlds like ours according to the book the dæmons are invisible but nevertheless exist to try to to see it you have to open your mind and it will appear the dæmon of a child is an animal but it does not have a definitive form and changes at will according to the circumstances but at puberty of the child the dæmon takes a definitive form which reflects the personality of the person the dæmon is generally of the opposite sex to that of his human however in certain cases the dæmon is of the same sex as his human which is interpreted by many readers as a sign of the homosexuality of this character philip pullman indicates that he did not have this intention but that it is possible just as it could indicate a gift of double vision he says in an interview it is also never explained at any point in the book how dæmons are born and in what form to touch the dæmon']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_translated[\"fr\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find domain-specific keywords\n",
    "\n",
    "Find the most frequent words in the documents, exlude the 1000 most used words in the English language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Concat the keywords with the original query\n",
    "\n",
    "Concatenate the keywords with the original query and search for documents in the original language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "Evaluate the results of the search\n",
    "\n",
    "Reference:\n",
    "1. GitHub: [pyterrier/examples/notebooks\n",
    "/retrieval_and_evaluation.ipynb](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/retrieval_and_evaluation.ipynb)\n",
    "1. GitHub: [pyterrier/examples/notebooks\n",
    "/experiment.ipynb](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/experiment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Precision / Recall\n",
    "\n",
    "See how many of the returned documents are relevant. Did the number of relevant documents increase?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Keyword diversification\n",
    "\n",
    "Did the number of unique keywords increase compared to naive domain-specific keyword identification?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
