{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "\n",
    "Libraries used:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in ./.venv/lib/python3.10/site-packages (1.26.4)\n",
      "Requirement already satisfied: deep-translator in ./.venv/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in ./.venv/lib/python3.10/site-packages (from deep-translator) (4.12.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.23.0 in ./.venv/lib/python3.10/site-packages (from deep-translator) (2.31.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./.venv/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.2.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install numpy deep-translator python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "env = dotenv_values(\".env\")  # replace \".env\" with your actual .env file path\n",
    "\n",
    "if (env[\"LANGUAGE_DETECT_API_KEY\"] == \"YOUR API KEY\"):\n",
    "  raise Exception(\"Please replace 'YOUR API KEY' with your actual API key in the .env file\")\n",
    "\n",
    "detection_api_key = env[\"LANGUAGE_DETECT_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langdetect import detect\n",
    "import deep_translator as dt\n",
    "from deep_translator import GoogleTranslator, single_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version: 1.26.4\n",
      "deep-translator version: 1.9.1\n"
     ]
    }
   ],
   "source": [
    "print(\"numpy version:\", np.__version__)\n",
    "print(\"deep-translator version:\", dt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Query formulation\n",
    "\n",
    "Let the end-user determine what they would like to find\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "q0 = \"How do I repair my bike?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Query language identification\n",
    "\n",
    "Identify the language of the query with the help of the ... library\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "l0 = single_detection(q0, api_key=detection_api_key)\n",
    "print(l0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Query translation\n",
    "\n",
    "Translate the query into Dutch, English, French, German, Italian, Portuguese, Russian, Spanish, and Chineese. Exlude the original language of the query from the translation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'en': 'How do I repair my bike?', 'nl': 'Hoe repareer ik mijn fiets?', 'fr': 'Comment réparer mon vélo ?', 'de': 'Wie repariere ich mein Fahrrad?', 'it': 'Come riparo la mia bicicletta?', 'pt': 'Como faço para consertar minha bicicleta?', 'ru': 'Как мне отремонтировать свой велосипед?', 'es': '¿Cómo reparo mi bicicleta?', 'zh-CN': '如何修理我的自行车？'}\n"
     ]
    }
   ],
   "source": [
    "qs = dict({l0: q0})\n",
    "\n",
    "languages = [\"nl\", \"en\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"es\", \"zh-CN\"]\n",
    "\n",
    "for lang in languages:\n",
    "    if lang != l0:\n",
    "        qs[lang] = translated = GoogleTranslator(source=l0, target=lang).translate(\n",
    "            text=q0\n",
    "        )\n",
    "\n",
    "print(qs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Search for documents in the target language\n",
    "\n",
    "Search for documents in the target language using the translated queries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "1. MLWIKIR: APython toolkit for building large-scale Wikipedia-based Information Retrieval Datasets in Chinese, English, French, Italian, Japanese, Spanish and more. [Research paper](https://www.irit.fr/CIRCLE/wp-content/uploads/2020/06/CIRCLE20_22.pdf)\n",
    "1. [pyterrier jupyter notebook example of spanish document retreival](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/non_en_retrieval.ipynb)\n",
    "1. [WikIR rawa datasets](https://ir-datasets.com/wikir.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(query, target_language=\"es\") -> list[str]:\n",
    "    return NotImplemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "documents: Dict[str, list[str]] = dict()\n",
    "\n",
    "for lang, q in qs.items():\n",
    "    documents[lang] = search(q, lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Document translation\n",
    "\n",
    "Translate the documents back to English to be processed by other algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NotImplementedType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m documents_translated: Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m lang, docs \u001b[38;5;129;01min\u001b[39;00m documents\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m----> 4\u001b[0m     documents_translated[lang] \u001b[38;5;241m=\u001b[39m [GoogleTranslator(source\u001b[38;5;241m=\u001b[39mlang, target\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtranslate(text\u001b[38;5;241m=\u001b[39md) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m docs]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NotImplementedType' object is not iterable"
     ]
    }
   ],
   "source": [
    "documents_translated: Dict[str, list[str]] = dict()\n",
    "\n",
    "for lang, docs in documents.items():\n",
    "    documents_translated[lang] = [\n",
    "        GoogleTranslator(source=lang, target=\"en\").translate(text=d) for d in docs\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Find domain-specific keywords\n",
    "\n",
    "Find the most frequent words in the documents, exlude the 1000 most used words in the English language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Concat the keywords with the original query\n",
    "\n",
    "Concatenate the keywords with the original query and search for documents in the original language\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "Evaluate the results of the search\n",
    "\n",
    "Reference:\n",
    "1. GitHub: [pyterrier/examples/notebooks\n",
    "/retrieval_and_evaluation.ipynb](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/retrieval_and_evaluation.ipynb)\n",
    "1. GitHub: [pyterrier/examples/notebooks\n",
    "/experiment.ipynb](https://github.com/terrier-org/pyterrier/blob/master/examples/notebooks/experiment.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Precision\n",
    "\n",
    "See how many of the returned documents are relevant. Did the number of relevant documents increase?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Keyword diversification\n",
    "\n",
    "Did the number of unique keywords increase compared to naive domain-specific keyword identification?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
